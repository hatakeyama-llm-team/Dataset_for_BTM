{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mecabで分かち書きしながら、tokenizeする\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "target_path=\"/data/hatakeyama/python/llm_corpus/corpus_scale_500.jsonl\"\n",
    "lines=[]\n",
    "with open(target_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        lines.append(json.loads(line)[\"text\"])\n",
    "\n",
    "with open(\"../data/corpus_text.txt\",\"w\") as f:\n",
    "    f.write(\"\")\n",
    "with open(\"../data/corpus_text.txt\",\"a\") as f:\n",
    "    for line in lines:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#わかちがき\n",
    "!mecab -F\"%M||||\" -E\"\\n\" -b 100000 < ../data/corpus_text.txt  > ../data/corpus_text.txt.tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import sentencepiece as spm\n",
    "import sys\n",
    "import yaml\n",
    "import os\n",
    "from special_token_list import *\n",
    "\n",
    "\n",
    "def yaml_to_namespace(yaml_path):\n",
    "    with open(yaml_path, 'r') as file:\n",
    "        # YAMLファイルを辞書として読み込む\n",
    "        data = yaml.safe_load(file)\n",
    "        # 辞書をSimpleNamespaceに変換\n",
    "        return recursive_namespace(data)\n",
    "\n",
    "\n",
    "def recursive_namespace(data):\n",
    "    if isinstance(data, dict):\n",
    "        # 再帰的に辞書の各要素をSimpleNamespaceに変換\n",
    "        return SimpleNamespace(**{k: recursive_namespace(v) for k, v in data.items()})\n",
    "    elif isinstance(data, list):\n",
    "        # リストの要素も変換\n",
    "        return [recursive_namespace(v) for v in data]\n",
    "    else:\n",
    "        # その他のデータ型はそのまま返す\n",
    "        return data\n",
    "\n",
    "\n",
    "args = yaml_to_namespace('../30tokenize/config.yaml')\n",
    "\n",
    "args.input=\"../data/corpus_text.txt.tok\"\n",
    "#args.vocab_size=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.train(\n",
    "        input=args.input,\n",
    "        model_prefix=args.model_prefix,\n",
    "        vocab_size=args.vocab_size,\n",
    "        character_coverage=args.character_coverage,\n",
    "        model_type=args.model_type,\n",
    "        num_threads=args.num_threads,\n",
    "        train_extremely_large_corpus=args.train_extremely_large_corpus,\n",
    "        user_defined_symbols=[\n",
    "            BOS_TOKEN,\n",
    "            EOS_TOKEN,\n",
    "            PAD_TOKEN,\n",
    "            CLS_TOKEN,\n",
    "            SEP_TOKEN,\n",
    "            EOD_TOKEN,\n",
    "            MASK_TOKEN,\n",
    "            NEWLINE_TOKEN,\n",
    "            EXTRA_TOKEN1,\n",
    "            EXTRA_TOKEN2,\n",
    "            EXTRA_TOKEN3,\n",
    "            EXTRA_TOKEN4,\n",
    "        ],  # Note: `NEWLINE_TOKEN` is needed in `user_defined_symbols`.\n",
    "        byte_fallback=True,\n",
    "        split_digits=True,\n",
    "        allow_whitespace_only_pieces=True,\n",
    "        remove_extra_whitespaces=False,\n",
    "        pretokenization_delimiter=\"||||\",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
