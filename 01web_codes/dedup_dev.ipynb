{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#from hojichar.document_filters import GenerateDedupLSH\n",
    "\n",
    "from src.Dedup import DedupManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache found, initializing new cache.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 463/1280 [03:34<06:19,  2.16it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m manager\u001b[38;5;241m=\u001b[39mDedupManager(batch_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/hatakeyama/python/Dataset_for_BTM/01web_codes/src/Dedup.py:72\u001b[0m, in \u001b[0;36mDedupManager.process_dir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m path_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_path_list()\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m tqdm(path_list):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_state()\n",
      "File \u001b[0;32m/media/hatakeyama/python/Dataset_for_BTM/01web_codes/src/Dedup.py:105\u001b[0m, in \u001b[0;36mDedupManager.process_path\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    102\u001b[0m make_dir(dir_name)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m target_text_list:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeduplicator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_duplicated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    107\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(json\u001b[38;5;241m.\u001b[39mdumps({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text},\n\u001b[1;32m    108\u001b[0m                     ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/hatakeyama/python/Dataset_for_BTM/01web_codes/src/Dedup.py:29\u001b[0m, in \u001b[0;36mDeduplicator.is_duplicated\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_duplicated\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m     28\u001b[0m     doc \u001b[38;5;241m=\u001b[39m Document(text)\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhasher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lsh \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mdedup_lsh:\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lsh \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen:\n",
      "File \u001b[0;32m~/miniconda3/envs/textprocess/lib/python3.12/site-packages/hojichar/filters/deduplication.py:186\u001b[0m, in \u001b[0;36mGenerateDedupLSH.apply\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc: Document) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Document:\n\u001b[1;32m    108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    編集距離の近い文書ではハッシュが類似します。次の例では、5番目のハッシュは完全一致し、`LSHDeduplicator` で重複と判定されます。\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    >>> from pprint import pprint\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m     '19+ac5cb320794cc2ce1f94c09adcc3a996a6d986c2']\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     lshs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_lsh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     doc\u001b[38;5;241m.\u001b[39mdedup_lsh \u001b[38;5;241m=\u001b[39m lshs\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "File \u001b[0;32m~/miniconda3/envs/textprocess/lib/python3.12/site-packages/hojichar/filters/deduplication.py:85\u001b[0m, in \u001b[0;36mGenerateDedupLSH.calc_lsh\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     83\u001b[0m     hashfunc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhashfunc_signed_32_from_seed(seed)\n\u001b[1;32m     84\u001b[0m     minhash \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_minhash(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_gram_tokenize(text, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_GRAM), hashfunc)\n\u001b[0;32m---> 85\u001b[0m     fingerprints\u001b[38;5;241m.\u001b[39mappend(minhash)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# 速度のためにリスト内包で書いており, 可読性低め\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# 各 fingerprint 16進数表記にして, 下四桁をバケットサイズ個ずつ連結している\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# TODO Python だとオーバーヘッドが大きいので, C++ で実装しなおす\u001b[39;00m\n\u001b[1;32m     90\u001b[0m lshs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    manager=DedupManager(batch_id=i)\n",
    "    manager.process_dir()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textprocess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
